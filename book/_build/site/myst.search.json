{"version":"1","records":[{"hierarchy":{"lvl1":"fNIRS Hyperscanning study preparation for analysis"},"type":"lvl1","url":"/fnirs-getting-started","position":0},{"hierarchy":{"lvl1":"fNIRS Hyperscanning study preparation for analysis"},"content":"Author: Patrice Fortin\n\nDate: 2025-01-06\n\nThe following Jupyter Notebook shows how to go from raw fNIRS hyperscanning recordings to produce an output file suitable for statistical analysis of Inter-Brain Synchrony (IBS).\n\nThe output file can be of .csv or .feather.\n\nFor an analysis example in R language, see tutorial/fnirs_study_example.R.\n\nFor an in-depth exploration of wavelet transforms, see tutorial/wavelet_exploration.ipynb\n\nFor an complete walkthrough of fnirs data inspection at every step, see tutorial/fnirs_recording_inspection.ipynb\n\n","type":"content","url":"/fnirs-getting-started","position":1},{"hierarchy":{"lvl1":"fNIRS Hyperscanning study preparation for analysis","lvl2":"Load libraries"},"type":"lvl2","url":"/fnirs-getting-started#load-libraries","position":2},{"hierarchy":{"lvl1":"fNIRS Hyperscanning study preparation for analysis","lvl2":"Load libraries"},"content":"\n\nimport re\nfrom collections import OrderedDict, defaultdict\nimport matplotlib.pyplot as plt\n\n\n\n%load_ext IPython.extensions.autoreload\n%autoreload 2\n\nimport hypyp.fnirs as fnirs\nfrom hypyp.wavelet import ComplexMorletWavelet\nfrom hypyp.utils import Task, TASK_NEXT_EVENT\n\n\n\n","type":"content","url":"/fnirs-getting-started#load-libraries","position":3},{"hierarchy":{"lvl1":"fNIRS Hyperscanning study preparation for analysis","lvl2":"Download and load raw data from disk"},"type":"lvl2","url":"/fnirs-getting-started#download-and-load-raw-data-from-disk","position":4},{"hierarchy":{"lvl1":"fNIRS Hyperscanning study preparation for analysis","lvl2":"Download and load raw data from disk"},"content":"To use as example, we download the dataset “Dataset of parent-child hyperscanning fNIRS recordings” from \n\nhttps://​researchdata​.ntu​.edu​.sg​/dataset​.xhtml​?persistentId​=​doi:10​.21979​/N9​/35DNCW\n\nbrowser = fnirs.DataBrowser()\ndir = browser.download_demo_dataset()\n\n\n\n\nPrepare dyads paths (parent+child) for file loading\n\n# Get the paths for dyads\n\npaths = [path for path in browser.list_all_files() if 'fathers' in path]\n\ndyad_paths = defaultdict(dict)\n\nfor path in paths:\n    m = re.search(r'(FCS\\d\\d)', path)\n    dyad_label = m.group(1)\n\n    if 'child' in path:\n        dyad_paths[dyad_label]['child'] = path\n\n    if 'parent' in path:\n        dyad_paths[dyad_label]['parent'] = path\n\nprint(dyad_paths)\n\n\n\n\n","type":"content","url":"/fnirs-getting-started#download-and-load-raw-data-from-disk","position":5},{"hierarchy":{"lvl1":"fNIRS Hyperscanning study preparation for analysis","lvl2":"Regions of Interest"},"type":"lvl2","url":"/fnirs-getting-started#regions-of-interest","position":6},{"hierarchy":{"lvl1":"fNIRS Hyperscanning study preparation for analysis","lvl2":"Regions of Interest"},"content":"Let’s define some region of interest, from \n\nhttps://​www​.nature​.com​/articles​/s41598​-019​-47810-4 Figure 3.\n\n# dummy values\nchannel_roi = fnirs.ChannelROI(OrderedDict({\n    'frontal_left': [\n        'S2_D3 hbo', # 4,\n        'S3_D3 hbo', # 6,\n        'S3_D4 hbo', # 7,\n        'S5_D3 hbo', # 11,\n    ],\n    'medial_left':[\n        'S1_D1 hbo', # 1,\n        'S1_D2 hbo', # 2,\n        'S2_D1 hbo', # 3,\n        'S3_D2 hbo', # 5,\n        'S4_D2 hbo', # 8,\n    ],\n    'central': [\n        'S4_D4 hbo', # 9,\n        'S5_D4 hbo', # 12,\n    ],\n    'frontal_right': [\n        'S5_D6 hbo', # 13,\n        'S6_D4 hbo', # 14,\n        'S6_D6 hbo', # 16,\n        'S8_D6 hbo', # 19,\n    ],\n    'medial_right':[\n        'S4_D5 hbo', # 10,\n        'S6_D5 hbo', # 15,\n        'S7_D5 hbo', # 17,\n        'S7_D7 hbo', # 18,\n        'S8_D7 hbo', # 20\n    ],\n}))\n\n\n\n\n","type":"content","url":"/fnirs-getting-started#regions-of-interest","position":7},{"hierarchy":{"lvl1":"fNIRS Hyperscanning study preparation for analysis","lvl2":"One dyad example"},"type":"lvl2","url":"/fnirs-getting-started#one-dyad-example","position":8},{"hierarchy":{"lvl1":"fNIRS Hyperscanning study preparation for analysis","lvl2":"One dyad example"},"content":"As a simple example, let’s look at a single inter-subject coherence.\n\nLet’s define some task for demonstration of how we can use time based tasks.\n\nTake a look at fnirs.Recording constructor if you have event based tasks.\n\nNOTE: The tasks here do not correspond the the actual conditions from the dataset. They are set as an example on how to use the toolbox.\n\n# Get connectivity matrix intra-subject for validation\n\ndyad_label = list(dyad_paths.keys())[0]\ndyad_info = list(dyad_paths.values())[0]\ntasks = [Task('one_minute', onset_time=0, duration=60)]\n\n# Example if you have tasks from events in the recordings\n#tasks = [\n#    Task('baseline', onset_event_id=1, offset_event_id=TASK_NEXT_EVENT),\n#    Task('task1',    onset_event_id=2, offset_event_id=TASK_NEXT_EVENT),\n#    Task('task2',    onset_event_id=3, offset_event_id=TASK_NEXT_EVENT),\n#    Task('task3',    onset_event_id=4, offset_event_id=TASK_NEXT_EVENT),\n#]\n\n# use a preprocessor to transform the cw amplitude data to hemoglobin concentration\npreprocessor = fnirs.MnePreprocessorRawToHaemo()\n\ns1 = fnirs.Recording(tasks=tasks, channel_roi=channel_roi).load_file(dyad_info['child'], preprocessor)\ns2 = fnirs.Recording(tasks=tasks, channel_roi=channel_roi).load_file(dyad_info['parent'], preprocessor)\n\ndyad = fnirs.Dyad(s1, s2, label=dyad_label)\ndyad.compute_wtcs(\n    ch_match='hbo',     # which channels to match\n    bin_seconds=15,     # split in bins of 15 seconds\n    period_cuts=[5, 10],    # split higher and lower frequencies for comparison\n)\n\ndyad.df[['dyad','subject1','subject2','roi1','roi2','channel1','channel2','task','epoch','bin','coherence']]\n\n\n\n\n\nWavelet Transform Coherence (WTC) details\n\nLet’s take a look at the Wavelet Transform Coherence. We take the first WTC to inspect it.\n\nwtc = dyad.wtcs[0]\n_ = wtc.plot(use_periods=True)\n\n\n\n\n","type":"content","url":"/fnirs-getting-started#one-dyad-example","position":9},{"hierarchy":{"lvl1":"fNIRS Hyperscanning study preparation for analysis","lvl3":"Computation validation","lvl2":"One dyad example"},"type":"lvl3","url":"/fnirs-getting-started#computation-validation","position":10},{"hierarchy":{"lvl1":"fNIRS Hyperscanning study preparation for analysis","lvl3":"Computation validation","lvl2":"One dyad example"},"content":"In order to be confident in the above results, let’s look at intermediary results.\n\nThe above Wavelet Transform Coherence (WTC) is a computed from the 2 Continuous Wavelet Transforms (CWT):\n\nfig, axes = plt.subplots(1, 2, sharey=True, figsize=(12, 4))\nwtc.cwt1.plot(ax=axes[0])\nwtc.cwt2.plot(ax=axes[1])\nfig.suptitle(f\"{dyad.s1.subject_label} / {dyad.s2.subject_label}\")\n\n\n\n\nThe Continuous Wavelet Transforms (CWTs) come from the hemoglobin that has been computed from the raw cw amplitudes in the signal.\n\nLet’s take a look at the original data and its Continuous Wavelet Transform. For more details on visualizing the Continuous\nWavelet Transform and all the filtering steps, see fnirs_recording_inspection.ipynb notebook.\n\nfig = dyad.s1.plot_steps_for_channel(wtc.label_ch1)\nfig.suptitle(f\"{dyad.s1.subject_label}: \" + fig.get_suptitle())\nplt.show()\nfig = dyad.s2.plot_steps_for_channel(wtc.label_ch2)\nfig.suptitle(f\"{dyad.s2.subject_label}: \" + fig.get_suptitle())\nplt.show()\n\n\n\n\n\n\n\n_ = dyad.plot_coherence_matrix_per_channel().axes[0].set_title('Dyad coherence per channel')\n\n\n\n\n\n_ = dyad.plot_coherence_matrix_per_roi().axes[0].set_title('Dyad coherence per region')\n\n\n\n\n","type":"content","url":"/fnirs-getting-started#computation-validation","position":11},{"hierarchy":{"lvl1":"fNIRS Hyperscanning study preparation for analysis","lvl2":"Study"},"type":"lvl2","url":"/fnirs-getting-started#study","position":12},{"hierarchy":{"lvl1":"fNIRS Hyperscanning study preparation for analysis","lvl2":"Study"},"content":"\n\n","type":"content","url":"/fnirs-getting-started#study","position":13},{"hierarchy":{"lvl1":"fNIRS Hyperscanning study preparation for analysis","lvl3":"Study Coherence processing","lvl2":"Study"},"type":"lvl3","url":"/fnirs-getting-started#study-coherence-processing","position":14},{"hierarchy":{"lvl1":"fNIRS Hyperscanning study preparation for analysis","lvl3":"Study Coherence processing","lvl2":"Study"},"content":"We now apply the same strategy on a cohort of dyads. We define a baseline task and a sample task.\n\nThe resulting is a Study object, which encapsulates all the logic of processing, computing WTC and preparing pandas dataframe for analysis.\n\n# Instanciate recordings and dyads objects\n\npreprocessor = fnirs.MnePreprocessorRawToHaemo()\ntasks = [\n    Task('first_minute', onset_time=0, duration=60),\n    Task('second_minute', onset_time=60, duration=60),\n]\n\nn_dyads = 10\nall_dyads = []\n\n# truncate for this example\ndyad_paths_keys = list(dyad_paths.keys())[:n_dyads]\n\nfor dyad_key in dyad_paths_keys:\n    dyad = fnirs.Dyad(\n        fnirs.Recording(tasks=tasks, channel_roi=channel_roi).load_file(dyad_paths[dyad_key]['child'], preprocessor),\n        fnirs.Recording(tasks=tasks, channel_roi=channel_roi).load_file(dyad_paths[dyad_key]['parent'], preprocessor),\n        label=dyad_key,\n    )\n    all_dyads.append(dyad)\n\nstudy = fnirs.Study(all_dyads)\n\n\n\n\n\n","type":"content","url":"/fnirs-getting-started#study-coherence-processing","position":15},{"hierarchy":{"lvl1":"fNIRS Hyperscanning study preparation for analysis","lvl3":"Wavelet object","lvl2":"Study"},"type":"lvl3","url":"/fnirs-getting-started#wavelet-object","position":16},{"hierarchy":{"lvl1":"fNIRS Hyperscanning study preparation for analysis","lvl3":"Wavelet object","lvl2":"Study"},"content":"Let’s define our wavelet object. The following code simple instanciates the default wavelet. We do it explicitely for the sake of demonstration only.\n\nThe Wavelet uses caching to avoid recomputing continuous wavelet transforms all the time for the same channels.\n\nSince the cache dictionary is shared by all dyads, a new pair with pre-computed CWT for channels will be much faster.\n\nThe cache is simply a python dictionary.\n\ncache = dict()\nwavelet = ComplexMorletWavelet(cache=cache)\n\n\n\n\nstudy.compute_wtcs(\n    ch_match='hbo',     # compute coherence only on oxyhemoglobin channels\n    wavelet=wavelet,    # use our predefined wavelet\n    with_intra=True,    # compute intra subject for nicer display in quadrants\n    bin_seconds=15,     # split in 10 seconds bins weight balancing. See `fnirs_wavelet_exploration.ipynb` for more details\n    period_cuts=[5,10], # split frequencies in lower/higher to visualize which range has a higher coherence\n    downsample=100,     # downsamples the wtc results for saving memory and allows faster display in plots\n    verbose=False,      # use this flag to see the progress of processing\n    # If memory usage gets too big during the processing, consider dropping the WTCs and store only the mean coherence\n    #keep_wtcs=False,   # delete computed WTCs after run, to avoid storing huge files\n)\n\n\n\n\n\n","type":"content","url":"/fnirs-getting-started#wavelet-object","position":17},{"hierarchy":{"lvl1":"fNIRS Hyperscanning study preparation for analysis","lvl3":"Coherence matrix","lvl2":"Study"},"type":"lvl3","url":"/fnirs-getting-started#coherence-matrix","position":18},{"hierarchy":{"lvl1":"fNIRS Hyperscanning study preparation for analysis","lvl3":"Coherence matrix","lvl2":"Study"},"content":"Visualize the coherence matrix averaged over all dyads. Top left and bottom right are intra-subject coherence. Bottom left and top right are mirrors of the inter-subject coherence.\n\n_ = study.plot_coherence_matrix_per_channel(s1_label='Child', s2_label='Parent')\n\n\n\n\n\n_ = study.plot_coherence_matrix_per_roi(s1_label='Child', s2_label='Parent')\n\n\n\n\n\nThe study object now has a pandas dataframe object that can be used or stored for further analysis\n\ndf = study.df[study.df['is_intra'] == False]\ndf\n\n\n\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 10), subplot_kw={'projection': 'polar'})\n_ = study.plot_coherence_connectogram(s1_label='Child', s2_label='Parent', ax=ax)\n\n\n\n\n","type":"content","url":"/fnirs-getting-started#coherence-matrix","position":19},{"hierarchy":{"lvl1":"fNIRS Hyperscanning study preparation for analysis","lvl3":"Save to disk","lvl2":"Study"},"type":"lvl3","url":"/fnirs-getting-started#save-to-disk","position":20},{"hierarchy":{"lvl1":"fNIRS Hyperscanning study preparation for analysis","lvl3":"Save to disk","lvl2":"Study"},"content":"Multiple formats can be used to save the results to disk.\n\nFormat\n\nUse case\n\n.csv\n\nTypical CSV file with a header, for sharing and importing in another python script or an external analysis software\n\n.feather\n\nTypical pandas dataframe storage format, for further analysis\n\n.pickle\n\nUsed to reload the Study object for visualisation in a dashboard.\n\ncsv_file_path = '../data/results/fnirs_study_example.csv'\nstudy.save_csv(csv_file_path)\n\n\n\n\nfeather_file_path = '../data/results/fnirs_study_example.feather'\nstudy.save_feather(feather_file_path)\n\n\n\n\n# Save to disk\n\nresults_file_path = '../data/results/fnirs_study_example.pickle'\nstudy.save_pickle(results_file_path)\n\n\n","type":"content","url":"/fnirs-getting-started#save-to-disk","position":21},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook"},"type":"lvl1","url":"/getting-started","position":0},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook"},"content":"Authors : Guillaume Dumas, Anaël Ayrolles, Florence Brun\n\nDate : 2022-11-03\n\nThis notebook demonstrates the basic functionalities of the \n\nHyPyP library for hyperscanning EEG analysis.\n\nIn this notebook we:\n\nLoad libraries for core operations, data science, visualization, and EEG analysis (using MNE).\n\nSet analysis parameters such as frequency bands.\n\nLoad and preprocess data (including ICA correction and autoreject) for two participants.\n\nPerform analyses such as power spectral density (PSD) estimation and connectivity analysis.\n\nRun statistical tests (parametric and non-parametric cluster-based permutations) on the computed data.\n\nVisualize the results with sensor maps and connectivity projections in both 2D and 3D.\n\nThe expected outputs are cleaned EEG epochs, PSD values, connectivity matrices, statistical test results, and visualizations that help interpret inter- and intra-brain connectivity.\n\n","type":"content","url":"/getting-started","position":1},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl2":"Load useful libs"},"type":"lvl2","url":"/getting-started#load-useful-libs","position":2},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl2":"Load useful libs"},"content":"\n\n","type":"content","url":"/getting-started#load-useful-libs","position":3},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"Core","lvl2":"Load useful libs"},"type":"lvl3","url":"/getting-started#core","position":4},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"Core","lvl2":"Load useful libs"},"content":"\n\nimport io\nfrom copy import copy\nfrom collections import OrderedDict\nimport requests\nimport tempfile  # For creating temporary files\n\n\n\n","type":"content","url":"/getting-started#core","position":5},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"Data science","lvl2":"Load useful libs"},"type":"lvl3","url":"/getting-started#data-science","position":6},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"Data science","lvl2":"Load useful libs"},"content":"\n\nimport numpy as np\nimport scipy\n\n\n\n","type":"content","url":"/getting-started#data-science","position":7},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"Visualization","lvl2":"Load useful libs"},"type":"lvl3","url":"/getting-started#visualization","position":8},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"Visualization","lvl2":"Load useful libs"},"content":"\n\nimport matplotlib.pyplot as plt\n\n\n\n","type":"content","url":"/getting-started#visualization","position":9},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"MNE","lvl2":"Load useful libs"},"type":"lvl3","url":"/getting-started#mne","position":10},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"MNE","lvl2":"Load useful libs"},"content":"\n\nimport mne\n\n\n\n","type":"content","url":"/getting-started#mne","position":11},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"HyPyP","lvl2":"Load useful libs"},"type":"lvl3","url":"/getting-started#hypyp","position":12},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"HyPyP","lvl2":"Load useful libs"},"content":"\n\nfrom hypyp import prep \nfrom hypyp import analyses\nfrom hypyp import stats\nfrom hypyp import viz\n\n\n\n","type":"content","url":"/getting-started#hypyp","position":13},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl2":"Setting Analysis Parameters"},"type":"lvl2","url":"/getting-started#setting-analysis-parameters","position":14},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl2":"Setting Analysis Parameters"},"content":"We define the frequency bands used in the study. Here we use two bands within the Alpha range. We also use an OrderedDict to preserve the order of the bands.\n\n# Define frequency bands as a dictionary\nfreq_bands = {\n    'Alpha-Low': [7.5, 11],\n    'Alpha-High': [11.5, 13]\n}\n\n# Convert to an OrderedDict to keep the defined order\nfreq_bands = OrderedDict(freq_bands)\nprint('Frequency bands:', freq_bands)\n\n\n\n","type":"content","url":"/getting-started#setting-analysis-parameters","position":15},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl2":"Loading Data"},"type":"lvl2","url":"/getting-started#loading-data","position":16},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl2":"Loading Data"},"content":"In this section we download the EEG datasets for two participants, convert them to MNE Epochs, and equalize the number of epochs across participants.\n\nThe function get_data downloads a dataset from a given URL and saves it to a temporary file with an MNE-compatible filename.\n\n# Template URL for downloading participant data\nURL_TEMPLATE = \"https://github.com/ppsp-team/HyPyP/blob/master/data/participant{}-epo.fif?raw=true\"\n\ndef get_data(idx):\n    \"\"\"\n    Download EEG data for a given participant index and save it to a temporary file.\n    \n    Parameters:\n        idx (int): Participant index number.\n    \n    Returns:\n        str: File path of the temporary file containing the EEG data.\n    \"\"\"\n    \n    # Format the URL with the participant index\n    url = URL_TEMPLATE.format(idx)\n    \n    # Download the data\n    response = requests.get(url)\n    \n    # Save the content to a temporary file with the suffix '-epo.fif'\n    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\"-epo.fif\")\n    temp_file.write(response.content)\n    temp_file.close()\n    \n    return temp_file.name\n\n# Load epochs for two participants using MNE\nepo1 = mne.read_epochs(\n    get_data(1),\n    preload=True,\n) \n\nepo2 = mne.read_epochs(\n    get_data(2),\n    preload=True,\n)\n\n\n\nSince our example dataset was not initially dedicated to hyperscanning, we need to equalize the number of epochs between our two participants.\n\n# Equalize the number of epochs between participants\nmne.epochs.equalize_epoch_counts([epo1, epo2])\n\n# Define sampling frequency from the first participant's data\nsampling_rate = epo1.info['sfreq']\nprint('Sampling rate:', sampling_rate)\n\n\n\n","type":"content","url":"/getting-started#loading-data","position":17},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl2":"Preprocessing Epochs"},"type":"lvl2","url":"/getting-started#preprocessing-epochs","position":18},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl2":"Preprocessing Epochs"},"content":"","type":"content","url":"/getting-started#preprocessing-epochs","position":19},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"ICA Correction","lvl2":"Preprocessing Epochs"},"type":"lvl3","url":"/getting-started#ica-correction","position":20},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"ICA Correction","lvl2":"Preprocessing Epochs"},"content":"We perform Independent Component Analysis (ICA) on the data from both participants to identify and remove artefactual components. First, we compute the ICA using the HyPyP function ICA_fit and then choose the relevant components for artefact rejection using ICA_choice_comp.\n\n# Compute ICA for each participant with 15 components\nicas = prep.ICA_fit([\n    epo1, epo2\n],\n    n_components=15,\n    method='infomax',\n    fit_params=dict(extended=True),\n    random_state=42\n)\n\n# Select the relevant independent components for artefact rejection\ncleaned_epochs_ICA = prep.ICA_choice_comp(icas, [epo1, epo2])\nprint('ICA correction completed.')\n\n\n\nSelecting relevant Independant Components for artefact rejection on one participant, that will be transpose to the other participant and removing them for both.\n\nYou can also use the mne-icalabel to automatically detect the not brain related components. Since this library depends on machine learning frameworks with complicated dependancies, we did not include it in the base requirements of HyPyP. If you want to test this automated approach of ICA annotation, just install it using pip install mne-icalabel and use the function below:\n\nfrom mne_icalabel import label_components\n\ndef ICA_autocorrect(icas: list, epochs: list, verbose: bool = False) -> list:\n    \"\"\"\n    Automatically detect the ICA components that are not brain related and remove them.\n\n    Arguments:\n        icas: list of Independent Components for each participant (IC are MNE\n          objects).\n        epochs: list of 2 Epochs objects (for each participant). Epochs_S1\n          and Epochs_S2 correspond to a condition and can result from the\n          concatenation of Epochs from different experimental realisations\n          of the condition.\n          Epochs are MNE objects: data are stored in an array of shape\n          (n_epochs, n_channels, n_times) and parameters information is\n          stored in a disctionnary.\n        verbose: option to plot data before and after ICA correction, \n          boolean, set to False by default. \n\n    Returns:\n        cleaned_epochs_ICA: list of 2 cleaned Epochs for each participant\n          (the non-brain related IC have been removed from the signal).\n    \"\"\"\n\n    cleaned_epochs_ICA = []\n    for ica, epoch in zip(icas, epochs):\n        ica_with_labels_fitted = label_components(epoch, ica, method=\"iclabel\")\n        ica_with_labels_component_detected = ica_with_labels_fitted[\"labels\"]\n        # Remove non-brain components (take only brain components for each subject)\n        excluded_idx_components = [idx for idx, label in enumerate(ica_with_labels_component_detected) if label not in [\"brain\"]]\n        cleaned_epoch_ICA = mne.Epochs.copy(epoch)\n        cleaned_epoch_ICA.info['bads'] = []\n        ica.apply(cleaned_epoch_ICA, exclude=excluded_idx_components)\n        cleaned_epoch_ICA.info['bads'] = copy.deepcopy(epoch.info['bads'])\n        cleaned_epochs_ICA.append(cleaned_epoch_ICA)\n\n        if verbose:\n            epoch.plot(title='Before ICA correction', show=True)\n            cleaned_epoch_ICA.plot(title='After ICA correction',show=True)\n    return cleaned_epochs_ICA\n\ncleaned_epochs_ICA = ICA_autocorrect(icas, [epo1, epo2], verbose=True)\n\n","type":"content","url":"/getting-started#ica-correction","position":21},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"Autoreject","lvl2":"Preprocessing Epochs"},"type":"lvl3","url":"/getting-started#autoreject","position":22},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"Autoreject","lvl2":"Preprocessing Epochs"},"content":"In this cell, we apply the local AutoReject algorithm using HyPyP. This step automatically rejects or interpolates bad epochs/channels while ensuring that the same channels/epochs are removed across participants. Verbose output provides a before/after comparison.\n\n# Apply local AutoReject on the ICA-cleaned epochs\ncleaned_epochs_AR, dic_AR = prep.AR_local(\n    cleaned_epochs_ICA,\n    strategy=\"union\",\n    threshold=50.0,\n    verbose=True\n)\nprint('AutoReject completed.')\n\n\n\n","type":"content","url":"/getting-started#autoreject","position":23},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"Picking Preprocessed Epochs","lvl2":"Preprocessing Epochs"},"type":"lvl3","url":"/getting-started#picking-preprocessed-epochs","position":24},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"Picking Preprocessed Epochs","lvl2":"Preprocessing Epochs"},"content":"After cleaning, we separate the preprocessed epochs for each participant for further analysis.\n\n# Assign cleaned epochs to individual participant variables\npreproc_S1 = cleaned_epochs_AR[0]\npreproc_S2 = cleaned_epochs_AR[1]\nprint('Preprocessed epochs for both participants are ready.')\n\n\n\n","type":"content","url":"/getting-started#picking-preprocessed-epochs","position":25},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl2":"Analysing Data: Welch Power Spectral Density (PSD)"},"type":"lvl2","url":"/getting-started#analysing-data-welch-power-spectral-density-psd","position":26},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl2":"Analysing Data: Welch Power Spectral Density (PSD)"},"content":"Here we compute the PSD for each participant in the Alpha-Low band using the HyPyP analyses.pow function. The PSD values are averaged across epochs.\n\n# Compute PSD for participant 1 in the Alpha-Low band\npsd1 = analyses.pow(\n    preproc_S1,\n    fmin=7.5,\n    fmax=11,\n    n_fft=1000,\n    n_per_seg=1000,\n    epochs_average=True\n)\n\n# Compute PSD for participant 2 in the Alpha-Low band\npsd2 = analyses.pow(\n    preproc_S2,\n    fmin=7.5,\n    fmax=11,\n    n_fft=1000,\n    n_per_seg=1000,\n    epochs_average=True\n)\n\n# Combine PSD data into a single array\ndata_psd = np.array([psd1.psd, psd2.psd])\nprint('PSD analysis completed.')\n\n\n\n","type":"content","url":"/getting-started#analysing-data-welch-power-spectral-density-psd","position":27},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl2":"Connectivity Analysis"},"type":"lvl2","url":"/getting-started#connectivity-analysis","position":28},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl2":"Connectivity Analysis"},"content":"In this section we compute brain connectivity metrics.\n\nWe first compute the analytic signal per frequency band using analyses.compute_freq_bands.\n\nThen, we compute connectivity (using the ‘ccorr’ mode) and average across epochs.\n\nWe slice the resulting connectivity matrices to extract both inter-brain (between participants) and intra-brain (within a participant) connectivity values.\n\nA Z-score normalization is performed for illustration purposes.\n\n# Prepare data for connectivity analysis (combine both participants)\ndata_inter = np.array([preproc_S1, preproc_S2])\nresult_intra = []\n\n# Compute the analytic signal in each frequency band\ncomplex_signal = analyses.compute_freq_bands(\n    data_inter,\n    sampling_rate,\n    freq_bands,\n    filter_length=int(sampling_rate),  # Adjust filter length based on sampling rate\n    l_trans_bandwidth=5.0,  # Reduced transition bandwidth\n    h_trans_bandwidth=5.0\n)\n\n# Compute connectivity using cross-correlation ('ccorr') and average across epochs\nresult = analyses.compute_sync(complex_signal, mode='ccorr', epochs_average=True)\n\n# Determine the number of channels\nn_ch = len(epo1.info['ch_names'])\n\n# Slice the connectivity matrix to get inter-brain connectivity in the Alpha-Low band\nalpha_low, alpha_high = result[:, 0:n_ch, n_ch:2*n_ch]\n\n# For further analysis, choose the Alpha-Low band values\nvalues = alpha_low\n\n# Compute a Z-score normalized connectivity matrix\nC = (values - np.mean(values[:])) / np.std(values[:])\n\n# Process intra-brain connectivity for each participant\nfor i in [0, 1]:\n    # Slice intra-brain connectivity matrix\n    alpha_low, alpha_high = result[:, (i * n_ch):((i + 1) * n_ch), (i * n_ch): ((i + 1) * n_ch)]\n    values_intra = alpha_low\n    \n    # Remove self-connections\n    values_intra -= np.diag(np.diag(values_intra))\n    \n    # Compute Z-score normalization for intra connectivity\n    C_intra = (values_intra - np.mean(values_intra[:])) / np.std(values_intra[:])\n    result_intra.append(C_intra)\n\nprint('Connectivity analysis completed.')\n\n\n\n","type":"content","url":"/getting-started#connectivity-analysis","position":29},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl2":"Statistical Analyses"},"type":"lvl2","url":"/getting-started#statistical-analyses","position":30},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl2":"Statistical Analyses"},"content":"We perform several statistical tests on the computed PSD and connectivity data. These include:\n\nA parametric permutation t-test on the PSD values.\n\nNon-parametric cluster-based permutation tests for both PSD and connectivity data.\n\n","type":"content","url":"/getting-started#statistical-analyses","position":31},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl4":"1/ MNE test without any correction","lvl2":"Statistical Analyses"},"type":"lvl4","url":"/getting-started#id-1-mne-test-without-any-correction","position":32},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl4":"1/ MNE test without any correction","lvl2":"Statistical Analyses"},"content":"This function takes samples (observations) by number of tests (variables i.e. channels), thus PSD values are averaged in the frequency dimension\n\n# Compute mean PSD values for each channel across epochs for both participants\npsd1_mean = np.mean(psd1.psd, axis=1)\npsd2_mean = np.mean(psd2.psd, axis=1)\n\n# Combine the means into a single array for the t-test\nX = np.array([psd1_mean, psd2_mean])\n\n# Perform permutation t-test (using MNE) without correction for multiple comparisons\nT_obs, p_values, H0 = mne.stats.permutation_t_test(\n    X=X,\n    n_permutations=5000,\n    tail=0,\n    n_jobs=1\n)\nprint('Permutation t-test completed.')\n\n# Alternatively, compute statistical conditions using HyPyP's statsCond function\nstatsCondTuple = stats.statsCond(\n    data=data_psd,\n    epochs=preproc_S1,\n    n_permutations=5000,\n    alpha=0.05\n)\nprint('Statistical condition tuple computed.')\n\n\n\n","type":"content","url":"/getting-started#id-1-mne-test-without-any-correction","position":33},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"Non-parametric Cluster-Based Permutations","lvl2":"Statistical Analyses"},"type":"lvl3","url":"/getting-started#non-parametric-cluster-based-permutations","position":34},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"Non-parametric Cluster-Based Permutations","lvl2":"Statistical Analyses"},"content":"Here, we create a priori connectivity matrices based on sensor positions and then perform cluster-based permutation tests.\n\nIn this example, we create two fake groups (by replicating each participant’s PSD data with added noise) and run the permutation test.\n\n# Create connectivity matrix for a priori sensor connectivity using participant 1's sensor layout\ncon_matrixTuple = stats.con_matrix(preproc_S1, freqs_mean=psd1.freq_list)\nch_con_freq = con_matrixTuple.ch_con_freq\n\n# Create two fake groups by replicating the PSD data and adding a small noise\nnoise_level = 1e-6  # Small noise to break exact duplicates\ndata_group = [\n    np.array([psd1.psd + np.random.normal(0, noise_level, psd1.psd.shape) for _ in range(3)]),\n    np.array([psd2.psd + np.random.normal(0, noise_level, psd2.psd.shape) for _ in range(3)])\n]\n\n# Perform non-parametric cluster-based permutation test on the fake groups\nstatscondCluster = stats.statscondCluster(\n    data=data_group,\n    freqs_mean=psd1.freq_list,\n    ch_con_freq=scipy.sparse.bsr_matrix(ch_con_freq),\n    tail=1,\n    n_permutations=5000,\n    alpha=0.05\n)\nprint('Cluster-based permutation test for PSD completed.')\n\n\n\n","type":"content","url":"/getting-started#non-parametric-cluster-based-permutations","position":35},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"Comparing Intra-Brain Connectivity Between Participants","lvl2":"Statistical Analyses"},"type":"lvl3","url":"/getting-started#comparing-intra-brain-connectivity-between-participants","position":36},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"Comparing Intra-Brain Connectivity Between Participants","lvl2":"Statistical Analyses"},"content":"We now compute a connectivity matrix for intra-brain connectivity and perform a cluster-based permutation test comparing the two participants.\n\nAgain, we generate two fake groups by replicating each participant’s intra-brain connectivity data and adding noise.\n\nNote that for connectivity, values are computed for every integer in the frequency bin from fmin to fmax, freqs_mean=np.arange(fmin, fmax) whereas in PSD it depends on the n_fft parameter psd.freq_list\n\nFor CSD, values are averaged across each frequencies so you do not need to take frequency into account to correct clusters\n\n# Create connectivity matrix for intra-brain connectivity\ncon_matrixTuple = stats.con_matrix(\n    epochs=preproc_S1,\n    freqs_mean=np.arange(7.5, 11),\n    draw=False\n)\n\nch_con = con_matrixTuple.ch_con\n\n# Create fake groups for intra-brain connectivity analysis\nAlpha_Low = [\n    np.array([\n        result_intra[0] + np.random.normal(0, noise_level, result_intra[0].shape),\n        result_intra[0] + np.random.normal(0, noise_level, result_intra[0].shape)\n    ]),\n    np.array([\n        result_intra[1] + np.random.normal(0, noise_level, result_intra[1].shape),\n        result_intra[1] + np.random.normal(0, noise_level, result_intra[1].shape)\n    ])\n]\n\n# Run cluster-based permutation test for intra-brain connectivity\nstatscondCluster_intra = stats.statscondCluster(\n    data=Alpha_Low,\n    freqs_mean=np.arange(7.5, 11),\n    ch_con_freq=scipy.sparse.bsr_matrix(ch_con),\n    tail=1,\n    n_permutations=5000,\n    alpha=0.05\n)\nprint('Intra-brain connectivity cluster test completed.')\n\n\n\n","type":"content","url":"/getting-started#comparing-intra-brain-connectivity-between-participants","position":37},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"Comparing Inter-Brain Connectivity to Random Signal","lvl2":"Statistical Analyses"},"type":"lvl3","url":"/getting-started#comparing-inter-brain-connectivity-to-random-signal","position":38},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"Comparing Inter-Brain Connectivity to Random Signal","lvl2":"Statistical Analyses"},"content":"Finally, we compare inter-brain connectivity values to a random signal. In this case, no a priori connectivity matrix is used between the two participants. We again create fake groups and run the permutation test.\n\n# Create fake groups for inter-brain connectivity analysis\ndata = [\n    np.array([\n        values, \n        values + np.random.normal(0, 1e-6, values.shape)\n    ]), \n    np.array([\n        result_intra[0], \n        result_intra[0] + np.random.normal(0, 1e-6, result_intra[0].shape)\n    ])\n]\n\nprint(len(data[0][0]), len(data[0][1]), len(data[1][0]), len(data[1][1]))\n\n\n# Run cluster-based permutation test for inter-brain connectivity without connectivity priors\nstatscondCluster = stats.statscondCluster(\n    data=data,\n    freqs_mean=np.linspace(7.5, 11, data[0].shape[-1]),\n    ch_con_freq=None,\n    tail=0,\n    n_permutations=5000,\n    alpha=0.05\n)\nprint('Inter-brain connectivity cluster test completed.')\n\n\n\n","type":"content","url":"/getting-started#comparing-inter-brain-connectivity-to-random-signal","position":39},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl2":"Visualization"},"type":"lvl2","url":"/getting-started#visualization-1","position":40},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl2":"Visualization"},"content":"In this final section, we visualize the statistical results and connectivity maps. We use HyPyP visualization functions to:\n\nPlot sensor-level T-values for all sensors and for only significant sensors.\n\nVisualize inter-brain connectivity on 2D and 3D head models.\n\nVisualize intra-brain connectivity for each participant in both 2D and 3D.\n\nNote: We manually specify bad channels for visualization purposes.\n\n# Plot sensor-level T-values using the t-statistics computed earlier\nviz.plot_significant_sensors(\n    T_obs_plot=statsCondTuple.T_obs,\n    epochs=preproc_S1\n)\nprint('Sensor-level T-values plotted.')\n\n\n\n# Plot only the T-values for sensors that are statistically significant\nviz.plot_significant_sensors(\n    T_obs_plot=statsCondTuple.T_obs_plot,\n    epochs=preproc_S1\n)\nprint('Significant sensors T-values plotted.')\n\n\n\n","type":"content","url":"/getting-started#visualization-1","position":41},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"Visulization of inter-brain links projected","lvl2":"Visualization"},"type":"lvl3","url":"/getting-started#visulization-of-inter-brain-links-projected","position":42},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"Visulization of inter-brain links projected","lvl2":"Visualization"},"content":"on either 2D or 3D head models\n\nIt can be applied to Cohen’s D (C as done here) or statistical values (statscondCluster.F_obs or F_obs_plot) of inter-individual brain connectivity\n\nWe can defining manually bad channel for viz test:\n\nepo1.info['bads'] = ['F8', 'Fp2', 'Cz', 'O2']\nepo2.info['bads'] = ['F7', 'O1']\n\n\n\n","type":"content","url":"/getting-started#visulization-of-inter-brain-links-projected","position":43},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"Visualisation of brain connectivity in 2D and 3D","lvl2":"Visualization"},"type":"lvl3","url":"/getting-started#visualisation-of-brain-connectivity-in-2d-and-3d","position":44},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl3":"Visualisation of brain connectivity in 2D and 3D","lvl2":"Visualization"},"content":"Defining head model and adding sensors\n\nWarning, threshold=‘auto’ must be used carefully, it is calculated specifically for the dyad, and therefore does not allow comparability between different dyads.\n\n","type":"content","url":"/getting-started#visualisation-of-brain-connectivity-in-2d-and-3d","position":45},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl4":"Visualization of inter-brain connectivity in 2D","lvl3":"Visualisation of brain connectivity in 2D and 3D","lvl2":"Visualization"},"type":"lvl4","url":"/getting-started#visualization-of-inter-brain-connectivity-in-2d","position":46},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl4":"Visualization of inter-brain connectivity in 2D","lvl3":"Visualisation of brain connectivity in 2D and 3D","lvl2":"Visualization"},"content":"\n\nInter-brain Hilbert-based connectivity\n\nviz.viz_2D_topomap_inter(epo1, epo2, C, threshold='auto', steps=10, lab=True)\n\n\n\n","type":"content","url":"/getting-started#visualization-of-inter-brain-connectivity-in-2d","position":47},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl4":"Visualization of inter-brain connectivity in 3D","lvl3":"Visualisation of brain connectivity in 2D and 3D","lvl2":"Visualization"},"type":"lvl4","url":"/getting-started#visualization-of-inter-brain-connectivity-in-3d","position":48},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl4":"Visualization of inter-brain connectivity in 3D","lvl3":"Visualisation of brain connectivity in 2D and 3D","lvl2":"Visualization"},"content":"\n\nInter-brain Hilbert-based connectivity\n\nviz.viz_3D_inter(epo1, epo2, C, threshold='auto', steps=10, lab=False)\nprint('3D inter-brain connectivity visualization completed.')\n\n\n\n","type":"content","url":"/getting-started#visualization-of-inter-brain-connectivity-in-3d","position":49},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl4":"Visualization of intra-brain connectivity in 2D","lvl3":"Visualisation of brain connectivity in 2D and 3D","lvl2":"Visualization"},"type":"lvl4","url":"/getting-started#visualization-of-intra-brain-connectivity-in-2d","position":50},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl4":"Visualization of intra-brain connectivity in 2D","lvl3":"Visualisation of brain connectivity in 2D and 3D","lvl2":"Visualization"},"content":"\n\nIntra-brain Hilbert-based connectivity\n\nviz.viz_2D_topomap_intra(epo1, epo2,\n                         C1= result_intra[0],\n                         C2= result_intra[1],\n                         threshold='auto',\n                         steps=2,\n                         lab=False)\n\nprint('2D intra-brain connectivity map plotted.')\n\n\n\n","type":"content","url":"/getting-started#visualization-of-intra-brain-connectivity-in-2d","position":51},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl4":"Visualization of intra-brain connectivity in 3D","lvl3":"Visualisation of brain connectivity in 2D and 3D","lvl2":"Visualization"},"type":"lvl4","url":"/getting-started#visualization-of-intra-brain-connectivity-in-3d","position":52},{"hierarchy":{"lvl1":"HyPyP Demonstration Notebook","lvl4":"Visualization of intra-brain connectivity in 3D","lvl3":"Visualisation of brain connectivity in 2D and 3D","lvl2":"Visualization"},"content":"\n\nIntra-brain Hilbert-based connectivity\n\nviz.viz_3D_intra(epo1, epo2,\n                 C1= result_intra[0],\n                 C2= result_intra[1],\n                 threshold='auto',\n                 steps=10,\n                 lab=False,\n                )\n\nprint('3D intra-brain connectivity visualization completed.')\n\n","type":"content","url":"/getting-started#visualization-of-intra-brain-connectivity-in-3d","position":53},{"hierarchy":{"lvl1":"What is HyPyp?"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"What is HyPyp?"},"content":"“Hyperscanning” setups are used to simultaneously record brain activity from two or more individuals during social tasks and to investigate the co-variations in their brain activity related to their socio-behavioral interactions. The Hyperscanning Python Pipeline (HyPyP) is a open-source software package that allows to carry-out and interpret a wide range of inter-brain connectivity analyses.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"What is HyPyp?","lvl2":"About this book"},"type":"lvl2","url":"/#about-this-book","position":2},{"hierarchy":{"lvl1":"What is HyPyp?","lvl2":"About this book"},"content":"Note\n\nThis site is under active development.","type":"content","url":"/#about-this-book","position":3},{"hierarchy":{"lvl1":"What is HyPyp?","lvl2":"Another header"},"type":"lvl2","url":"/#another-header","position":4},{"hierarchy":{"lvl1":"What is HyPyp?","lvl2":"Another header"},"content":"","type":"content","url":"/#another-header","position":5},{"hierarchy":{"lvl1":"What is HyPyp?","lvl3":"third level header","lvl2":"Another header"},"type":"lvl3","url":"/#third-level-header","position":6},{"hierarchy":{"lvl1":"What is HyPyp?","lvl3":"third level header","lvl2":"Another header"},"content":"","type":"content","url":"/#third-level-header","position":7}]}